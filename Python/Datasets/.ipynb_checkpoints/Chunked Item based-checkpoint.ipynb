{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import findspark\n",
    "#useful to install this tool to simplify spark import\n",
    "findspark.init()\n",
    "from pyspark import  SparkContext\n",
    "sc = SparkContext( 'local[*]', 'pyspark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'35236', 1), (u'35182', 7), (u'35234', 2), (u'35232', 1), (u'4446', 2), (u'35230', 5), (u'31739', 2), (u'35548', 2), (u'20050', 6), (u'6972', 1)]\n",
      "FILE: from 1 to3\n",
      "[(u'19841', ([u'8', 2], [u'1665', 1.0, 4, 3]))]\n",
      "[((u'5', u'23213'), <pyspark.resultiterable.ResultIterable object at 0x106108850>)]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import csv\n",
    "from Similarities import sim_pearson\n",
    "top=\"33173 33475 1076 35300 15743\"\n",
    "train_rdd = sc.textFile(\"train_no_header.csv\")\n",
    "test_rdd = sc.textFile(\"test_no_header.csv\")\n",
    "\n",
    "num_vote_for_item_rdd=(train_rdd\n",
    "         .map(lambda x: x.split(','))\n",
    "         .map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "         .groupByKey()\n",
    "         .map(lambda x:(x[0],len(x[1]))))\n",
    "print num_vote_for_item_rdd.take(10)\n",
    "\n",
    "def test_item_filter(x):\n",
    "    for i in x[1]:\n",
    "        if i[0] in test_users:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def map_string (x):\n",
    "        y=x[1]\n",
    "        s=\"\"\n",
    "        \n",
    "        for i in y:\n",
    "            s+=str(i[0])+\" \"\n",
    "        z=len(y)\n",
    "        top_rates=[33173, 33475, 1076, 35300, 15743]\n",
    "        i=0\n",
    "        while (z<5):\n",
    "            s+=str(top_rates[i])\n",
    "            i+=1\n",
    "            z+=1\n",
    "        if (y[0][1]<8):\n",
    "            s=top\n",
    "        return x[0],s\n",
    "\n",
    "\n",
    "def compute_rec (x):\n",
    "    num=sum(i[0]*i[1] for i in x[1])\n",
    "    den=sum(i[1] for i in x[1])\n",
    "    if den==0:\n",
    "        return 0\n",
    "    return x[0][0],(x[0][1],float(num)/den)\n",
    "\n",
    "i=1\n",
    "k=2\n",
    "while (i<2):\n",
    "    f1= open('submission_item_based'+str(i)+'.csv','w+')\n",
    "    \n",
    "    print \"FILE: from \"+str(i)+\" to\"+str(i+k)\n",
    "    test_users=test_rdd.collect()[i:i+k]\n",
    "    #print test_users\n",
    "    test_item_votes_rdd=(train_rdd\n",
    "                     .map(lambda x: x.split(','))\n",
    "                     .map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "                     .groupByKey()\n",
    "                     .filter(test_item_filter)\n",
    "                     .map(lambda x: (x[0],list(x[1]))))\n",
    "                          \n",
    "\n",
    "    #print test_item_votes_rdd.take(2)\n",
    "        \n",
    "    rdd = train_rdd\n",
    "    rdd = rdd.map( lambda x: x.split(',') )\n",
    "    rdd = rdd.map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "\n",
    "    rdd = rdd.groupByKey()\n",
    "    rdd = rdd.map(lambda x:(x[0],list(x[1]),len(x[1])))\n",
    "\n",
    "\n",
    "\n",
    "    #computing similarities [test_voted_item,[item,sim,n_test_item_votes,n_item_votes]]\n",
    "    \n",
    "\n",
    "    sim_rdd=test_item_votes_rdd.cartesian(rdd)\n",
    "    sim_rdd=sim_rdd.map(lambda x: (x[0][0],[x[1][0],sim_pearson(x[0][1],x[1][1]),len(x[0][1]),len(x[1][1])])).filter(lambda x:x[1][1]>0 and x[1][0]!=x[0])\n",
    "\n",
    "    #print sim_rdd.take(1)\n",
    "    \n",
    "    #computing useful part of reverse urm \n",
    "    rev_urm_rdd=(train_rdd\n",
    "         .map(lambda x: x.split(','))\n",
    "         .filter(lambda x:x[0] in test_users)\n",
    "         .map(lambda x:(x[1],[x[0],int(x[2])])))\n",
    "    \n",
    "    \n",
    "\n",
    "    #grouping votes\n",
    "    vote_rdd=rev_urm_rdd.join(sim_rdd)\n",
    "    print vote_rdd.take(1)\n",
    "    grouped_vote_rdd=(vote_rdd\n",
    "                    .map(lambda x: ((x[1][0][0],x[1][1][0]),(x[1][0][1],x[1][1][1])))\n",
    "                    .groupByKey())\n",
    "\n",
    "    print grouped_vote_rdd.take(1)\n",
    "    #computing recommendations\n",
    "    rec_rdd=(grouped_vote_rdd\n",
    "         .map(compute_rec)\n",
    "         .groupByKey()\n",
    "         .map(lambda x: (x[0],(sorted(list(y for y in x[1]),key=lambda x: -x[1]))[0:])))\n",
    "    \n",
    "    \n",
    "    #print rec_rdd.take(4)\n",
    "    \n",
    "    #printing on file\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    recommendations_rdd=(rec_rdd\n",
    "                     .map(map_string)\n",
    "                     .takeOrdered(k+1,key=lambda x: int(x[0])))\n",
    "                    \n",
    "    recommended_users=list(item[0] for item in recommendations_rdd)\n",
    "    formatted_recommendations=recommendations_rdd;\n",
    "    csv_f1=csv.writer(f1)\n",
    "    m=0\n",
    "    n=0\n",
    "    while(m<k):\n",
    "        if (test_users[m] in recommended_users):\n",
    "            csv_f1.writerow(formatted_recommendations[n])\n",
    "            n+=1\n",
    "        else:\n",
    "            csv_f1.writerow((test_users[m],top))\n",
    "        m+=1\n",
    "        \n",
    "    i=i+k\n",
    "    f1.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'14703', u'14708', u'14709', u'14715', u'14716', u'14718', u'14720', u'14723', u'14726', u'14727', u'14728', u'14730', u'14733', u'14737', u'14738', u'14740', u'14749', u'14750', u'14751', u'14752', u'14756', u'14757', u'14760', u'14766', u'14769', u'14773', u'14775', u'14780', u'14781', u'14785', u'14787', u'14788', u'14789', u'14792', u'14794', u'14798', u'14801', u'14803', u'14809', u'14813', u'14815', u'14821', u'14833', u'14835', u'14843', u'14846', u'14851', u'14852', u'14854', u'14856', u'14859', u'14863', u'14864', u'14866', u'14869', u'14870', u'14873', u'14874', u'14876', u'14879', u'14883', u'14884', u'14890', u'14891', u'14893', u'14899', u'14908', u'14910', u'14911', u'14915', u'14917', u'14923', u'14926', u'14928', u'14930', u'14937', u'14939', u'14943', u'14947', u'14949', u'14950', u'14951', u'14952', u'14953', u'14955', u'14960', u'14970', u'14973', u'14978', u'14980', u'14985', u'14987', u'14988', u'14991', u'14993', u'14998', u'14999', u'15003', u'15008', u'15011', u'15012', u'15015', u'15017', u'15021', u'15026', u'15027', u'15028', u'15030', u'15031', u'15034', u'15035', u'15036', u'15040', u'15048', u'15053', u'15057', u'15059', u'15064', u'15076', u'15082', u'15089', u'15090', u'15091', u'15096', u'15100', u'15103', u'15108', u'15109', u'15111', u'15112', u'15113', u'15114', u'15115', u'15116', u'15118', u'15125', u'15126', u'15127', u'15130', u'15139', u'15149', u'15155', u'15158', u'15161', u'15162', u'15164', u'15168', u'15176', u'15180', u'15183', u'15184', u'15187', u'15193', u'15194', u'15195', u'15198', u'15215', u'15217', u'15218', u'15219', u'15221', u'15224', u'15226', u'15228', u'15230', u'15243', u'15246', u'15248', u'15250', u'15251', u'15269', u'15270', u'15273', u'15275', u'15276', u'15278', u'15289', u'15297', u'15299', u'15303', u'15309', u'15313', u'15316', u'15320', u'15328', u'15329', u'15330', u'15331', u'15332', u'15334', u'15337', u'15338', u'15350', u'15352', u'15360', u'15364']\n"
     ]
    }
   ],
   "source": [
    "#writing last file chunk\n",
    "import numpy\n",
    "import csv\n",
    "from Similarities import cosine_similarity\n",
    "if True:\n",
    "    f1= open('submission_item_based4000.csv','w+')\n",
    "    test_users=test_rdd.collect()[4000:4196]\n",
    "    print test_users\n",
    "    test_item_votes_rdd=(train_rdd\n",
    "                     .map(lambda x: x.split(','))\n",
    "                     .map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "                     .groupByKey()\n",
    "                     .filter(test_item_filter)\n",
    "                     .map(lambda x: (x[0],list(x[1]))))\n",
    "                          \n",
    "\n",
    "    rdd = train_rdd\n",
    "    rdd = rdd.map( lambda x: x.split(',') )\n",
    "    rdd = rdd.map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "\n",
    "    rdd = rdd.groupByKey()\n",
    "    rdd = rdd.map(lambda x:(x[0],list(x[1])))\n",
    "\n",
    "\n",
    "\n",
    "    #computing similarities\n",
    "    \n",
    "\n",
    "    sim_rdd=test_item_votes_rdd.cartesian(rdd)\n",
    "    sim_rdd=sim_rdd.map(lambda x: (x[0][0],[x[1][0],cosine_similarity(x[1][1],x[0][1])])).filter(lambda x:x[1][1]>0 and x[1][0]!=x[0])\n",
    "\n",
    "    #computing useful part of reverse urm \n",
    "    rev_urm_rdd=(train_rdd\n",
    "         .map(lambda x: x.split(','))\n",
    "         .filter(lambda x:x[0] in test_users)\n",
    "         .map(lambda x:(x[1],[x[0],int(x[2])])))\n",
    "\n",
    "    #grouping votes\n",
    "    vote_rdd=rev_urm_rdd.join(sim_rdd)\n",
    "    grouped_vote_rdd=(vote_rdd\n",
    "                    .map(lambda x: ((x[1][0][0],x[1][1][0]),(x[1][0][1],x[1][1][1])))\n",
    "                    .groupByKey())\n",
    "\n",
    "    #computing recommendations\n",
    "    rec_rdd=(grouped_vote_rdd\n",
    "         .map(compute_rec)\n",
    "         .groupByKey()\n",
    "         .map(lambda x: (x[0],(sorted(list(y for y in x[1]),key=lambda x: -x[1]))[0:5])))\n",
    "\n",
    "    \n",
    "    #printing on file\n",
    "    \n",
    "    \n",
    "    top=\"33173 33475 35300 1076 31992\"\n",
    "    \n",
    "    recommendations_rdd=(rec_rdd\n",
    "                     .map(map_string)\n",
    "                     .takeOrdered(196,key=lambda x: int(x[0])))\n",
    "                    \n",
    "    recommended_users=list(item[0] for item in recommendations_rdd)\n",
    "    formatted_recommendations=recommendations_rdd;\n",
    "    csv_f1=csv.writer(f1)\n",
    "    m=0\n",
    "    n=0\n",
    "    while(m<196):\n",
    "        if (test_users[m] in recommended_users):\n",
    "            csv_f1.writerow(formatted_recommendations[n])\n",
    "            n+=1\n",
    "        else:\n",
    "            csv_f1.writerow((test_users[m],top))\n",
    "        m+=1\n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#collecting results\n",
    "i=0\n",
    "rows=[[\"userId\",\"testItems\"]]\n",
    "while(i<4001):\n",
    "    f1= open('submission_item_based'+str(i)+'.csv','rb')\n",
    "    f1_csv=csv.reader(f1)\n",
    "    rows=rows+list(f1_csv)\n",
    "    i=i+200\n",
    "    f1.close()\n",
    "f1=open('submission_item_based_cosine.csv','w+')\n",
    "f1_csv=csv.writer(f1)\n",
    "f1_csv.writerows(rows)\n",
    "f1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
