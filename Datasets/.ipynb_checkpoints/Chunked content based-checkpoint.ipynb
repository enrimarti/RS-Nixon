{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import findspark\n",
    "#useful to install this tool to simplify spark import\n",
    "findspark.init()\n",
    "from pyspark import  SparkContext\n",
    "sc = SparkContext( 'local[*]', 'pyspark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: from 2020 to2030\n",
      "FILE: from 2030 to2040\n",
      "FILE: from 2040 to2050\n",
      "FILE: from 2050 to2060\n",
      "FILE: from 2060 to2070\n",
      "FILE: from 2070 to2080\n",
      "FILE: from 2080 to2090\n",
      "FILE: from 2090 to2100\n",
      "FILE: from 2100 to2110\n",
      "FILE: from 2110 to2120\n",
      "FILE: from 2120 to2130\n",
      "FILE: from 2130 to2140\n",
      "FILE: from 2140 to2150\n",
      "FILE: from 2150 to2160\n",
      "FILE: from 2160 to2170\n",
      "FILE: from 2170 to2180\n",
      "FILE: from 2180 to2190\n",
      "FILE: from 2190 to2200\n",
      "FILE: from 2200 to2210\n",
      "FILE: from 2210 to2220\n",
      "FILE: from 2220 to2230\n",
      "FILE: from 2230 to2240\n",
      "FILE: from 2240 to2250\n",
      "FILE: from 2250 to2260\n",
      "FILE: from 2260 to2270\n",
      "FILE: from 2270 to2280\n",
      "FILE: from 2280 to2290\n",
      "FILE: from 2290 to2300\n",
      "FILE: from 2300 to2310\n",
      "FILE: from 2310 to2320\n",
      "FILE: from 2320 to2330\n",
      "FILE: from 2330 to2340\n",
      "FILE: from 2340 to2350\n",
      "FILE: from 2350 to2360\n",
      "FILE: from 2360 to2370\n",
      "FILE: from 2370 to2380\n",
      "FILE: from 2380 to2390\n",
      "FILE: from 2390 to2400\n",
      "FILE: from 2400 to2410\n",
      "FILE: from 2410 to2420\n",
      "FILE: from 2420 to2430\n",
      "FILE: from 2430 to2440\n",
      "FILE: from 2440 to2450\n",
      "FILE: from 2450 to2460\n",
      "FILE: from 2460 to2470\n",
      "FILE: from 2470 to2480\n",
      "FILE: from 2480 to2490\n",
      "FILE: from 2490 to2500\n",
      "FILE: from 2500 to2510\n",
      "FILE: from 2510 to2520\n",
      "FILE: from 2520 to2530\n",
      "FILE: from 2530 to2540\n",
      "FILE: from 2540 to2550\n",
      "FILE: from 2550 to2560\n",
      "FILE: from 2560 to2570\n",
      "FILE: from 2570 to2580\n",
      "FILE: from 2580 to2590\n",
      "FILE: from 2590 to2600\n",
      "FILE: from 2600 to2610\n",
      "FILE: from 2610 to2620\n",
      "FILE: from 2620 to2630\n",
      "FILE: from 2630 to2640\n",
      "FILE: from 2640 to2650\n",
      "FILE: from 2650 to2660\n",
      "FILE: from 2660 to2670\n",
      "FILE: from 2670 to2680\n",
      "FILE: from 2680 to2690\n",
      "FILE: from 2690 to2700\n",
      "FILE: from 2700 to2710\n",
      "FILE: from 2710 to2720\n",
      "FILE: from 2720 to2730\n",
      "FILE: from 2730 to2740\n",
      "FILE: from 2740 to2750\n",
      "FILE: from 2750 to2760\n",
      "FILE: from 2760 to2770\n",
      "FILE: from 2770 to2780\n",
      "FILE: from 2780 to2790\n",
      "FILE: from 2790 to2800\n",
      "FILE: from 2800 to2810\n",
      "FILE: from 2810 to2820\n",
      "FILE: from 2820 to2830\n",
      "FILE: from 2830 to2840\n",
      "FILE: from 2840 to2850\n",
      "FILE: from 2850 to2860\n",
      "FILE: from 2860 to2870\n",
      "FILE: from 2870 to2880\n",
      "FILE: from 2880 to2890\n",
      "FILE: from 2890 to2900\n",
      "FILE: from 2900 to2910\n",
      "FILE: from 2910 to2920\n",
      "FILE: from 2920 to2930\n",
      "FILE: from 2930 to2940\n",
      "FILE: from 2940 to2950\n",
      "FILE: from 2950 to2960\n",
      "FILE: from 2960 to2970\n",
      "FILE: from 2970 to2980\n",
      "FILE: from 2980 to2990\n",
      "FILE: from 2990 to3000\n",
      "FILE: from 3000 to3010\n",
      "FILE: from 3010 to3020\n",
      "FILE: from 3020 to3030\n",
      "FILE: from 3030 to3040"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import csv\n",
    "from Similarities import sim_pearson\n",
    "top=\"33173 33475 1076 35300 15743\"\n",
    "train_rdd = sc.textFile(\"train_no_header.csv\")\n",
    "test_rdd = sc.textFile(\"test_no_header.csv\")\n",
    "feat_rdd=sc.textFile('icm_no_header.csv')\n",
    "\n",
    "feat_rdd=feat_rdd.map(lambda x: x.split(',')).map(lambda x: (x[0],[x[1]]))\n",
    "item_feat_rdd=feat_rdd.groupByKey().cache()\n",
    "\n",
    "avgVoteNumberPerItem=5.07044729863\n",
    "minimumVotesRequired=avgVoteNumberPerItem*0.8\n",
    "avgVote=6.81887639657\n",
    "\n",
    "    \n",
    "def jaccard_sim(feature1,feature2):\n",
    "    s1=set([feat[0] for feat in feature1])\n",
    "    s2=set([feat[0] for feat in feature2])\n",
    "    if len(s1 | s2)==0: return 0\n",
    "    return float(len(s1 & s2)) / len(s1 | s2)\n",
    "    \n",
    "\n",
    "\n",
    "def test_item_filter(x):\n",
    "    for i in x[1]:\n",
    "        if i[0] in test_users:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def map_string (x):\n",
    "        y=x[1]\n",
    "        s=\"\"\n",
    "        \n",
    "        for i in y:\n",
    "            s+=str(i[0])+\" \"\n",
    "        z=len(y)\n",
    "        top_rates=[33173, 33475, 1076, 35300, 15743]\n",
    "        i=0\n",
    "        while (z<5):\n",
    "            s+=str(top_rates[i])\n",
    "            i+=1\n",
    "            z+=1\n",
    "        return x[0],s\n",
    "\n",
    "\n",
    "\n",
    "def compute_rec (x):\n",
    "    num=sum(i[0]*i[1] for i in x[1])\n",
    "    den=sum(i[1] for i in x[1])\n",
    "    if den==0:\n",
    "        return x[0][0],(x[0][1],0)\n",
    "    return x[0][0],(x[0][1],num/den)\n",
    "\n",
    "#0:20-1820:40->20\n",
    "#1840:1850-2010:2020->10\n",
    "i=2020\n",
    "k=10\n",
    "while (i<4190):\n",
    "    f1= open('content_based/submission_content_based'+str(i)+'.csv','w+')\n",
    "    \n",
    "    print \"FILE: from \"+str(i)+\" to\"+str(i+k)\n",
    "    test_users=test_rdd.collect()[i:i+k]\n",
    "\n",
    "    test_item_votes_rdd=(train_rdd\n",
    "                     .map(lambda x: x.split(','))\n",
    "                     .map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "                     .groupByKey()\n",
    "                     .filter(test_item_filter)\n",
    "                     .map(lambda x: (x[0],list(x[1]))))\n",
    "    \n",
    "    \n",
    "    test_items=test_item_votes_rdd.map(lambda x:x[0]).collect()\n",
    "    #only the features for the item voted by the test users\n",
    "    test_item_feat_rdd=item_feat_rdd.filter(lambda x: x[0] in test_items)\n",
    "    test_item_feat_rdd.map(lambda x:(x[0], list(x[1]))).take(10)\n",
    "    test_items=test_item_votes_rdd.map(lambda x:x[0]).collect()\n",
    "\n",
    "    item_feat_rdd_cart = test_item_feat_rdd.cartesian(item_feat_rdd)\n",
    "    \n",
    "    test_item_item_sim = (item_feat_rdd_cart\n",
    "                      .map(lambda x: (x[0][0],[x[1][0],jaccard_sim(x[0][1],x[1][1])])))\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #computing similarities [test_voted_item,[item,sim,n_test_item_votes,n_item_votes]]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #print sim_rdd.take(1)\n",
    "    \n",
    "    #computing useful part of reverse urm \n",
    "    rev_urm_rdd=(train_rdd\n",
    "         .map(lambda x: x.split(','))\n",
    "         .filter(lambda x:x[0] in test_users)\n",
    "         .map(lambda x:(x[1],[x[0],int(x[2])])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #grouping votes\n",
    "    vote_rdd=rev_urm_rdd.join(test_item_item_sim)\n",
    "    grouped_vote_rdd=(vote_rdd\n",
    "                    .map(lambda x: ((x[1][0][0],x[1][1][0]),(x[1][0][1],x[1][1][1],x[0])))\n",
    "                    .groupByKey())\n",
    "\n",
    "    \n",
    "    #print grouped_vote_rdd.map(lambda x: (x[0],list(x[1]))).take(2)\n",
    "    #computing recommendations\n",
    "    rec_rdd=(grouped_vote_rdd\n",
    "         .map(compute_rec)\n",
    "         .groupByKey()\n",
    "         .map(lambda x: (x[0],(sorted(list(y for y in x[1]),key=lambda x: -x[1]))[0:5])))\n",
    "    \n",
    "    \n",
    "    recommendations_rdd=(rec_rdd\n",
    "                     .map(map_string)\n",
    "                     .takeOrdered(k+1,key=lambda x: int(x[0])))\n",
    "    \n",
    "    recommended_users=list(item[0] for item in recommendations_rdd)\n",
    "    formatted_recommendations=recommendations_rdd;\n",
    "    csv_f1=csv.writer(f1)\n",
    "    m=0\n",
    "    n=0\n",
    "    while(m<k):\n",
    "        if (test_users[m] in recommended_users):\n",
    "            csv_f1.writerow(formatted_recommendations[n])\n",
    "            n+=1\n",
    "        else:\n",
    "            csv_f1.writerow((test_users[m],top))\n",
    "        m+=1\n",
    "        \n",
    "    i=i+k\n",
    "    f1.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writing last file chunk\n",
    "i=4190\n",
    "k=6\n",
    "while (i<4190):\n",
    "    f1= open('content_based/submission_content_based'+str(i)+'.csv','w+')\n",
    "    \n",
    "    print \"FILE: from \"+str(i)+\" to\"+str(i+k)\n",
    "    test_users=test_rdd.collect()[i:i+k]\n",
    "\n",
    "    test_item_votes_rdd=(train_rdd\n",
    "                     .map(lambda x: x.split(','))\n",
    "                     .map(lambda x:(x[1],[x[0],int(x[2])]))\n",
    "                     .groupByKey()\n",
    "                     .filter(test_item_filter)\n",
    "                     .map(lambda x: (x[0],list(x[1]))))\n",
    "    \n",
    "    \n",
    "    test_items=test_item_votes_rdd.map(lambda x:x[0]).collect()\n",
    "    #only the features for the item voted by the test users\n",
    "    test_item_feat_rdd=item_feat_rdd.filter(lambda x: x[0] in test_items)\n",
    "    test_item_feat_rdd.map(lambda x:(x[0], list(x[1]))).take(10)\n",
    "    test_items=test_item_votes_rdd.map(lambda x:x[0]).collect()\n",
    "\n",
    "    item_feat_rdd_cart = test_item_feat_rdd.cartesian(item_feat_rdd)\n",
    "    \n",
    "    test_item_item_sim = (item_feat_rdd_cart\n",
    "                      .map(lambda x: (x[0][0],[x[1][0],jaccard_sim(x[0][1],x[1][1])])))\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #computing similarities [test_voted_item,[item,sim,n_test_item_votes,n_item_votes]]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #print sim_rdd.take(1)\n",
    "    \n",
    "    #computing useful part of reverse urm \n",
    "    rev_urm_rdd=(train_rdd\n",
    "         .map(lambda x: x.split(','))\n",
    "         .filter(lambda x:x[0] in test_users)\n",
    "         .map(lambda x:(x[1],[x[0],int(x[2])])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #grouping votes\n",
    "    vote_rdd=rev_urm_rdd.join(test_item_item_sim)\n",
    "    print \"VOTE:\"+str(vote_rdd.take(2))\n",
    "    \n",
    "    grouped_vote_rdd=(vote_rdd\n",
    "                    .map(lambda x: ((x[1][0][0],x[1][1][0]),(x[1][0][1],x[1][1][1],x[0])))\n",
    "                    .groupByKey())\n",
    "\n",
    "    print \"GROUPED:\"+str(grouped_vote_rdd.take(2)[1][1])\n",
    "    #print grouped_vote_rdd.map(lambda x: (x[0],list(x[1]))).take(2)\n",
    "    #computing recommendations\n",
    "    rec_rdd=(grouped_vote_rdd\n",
    "         .map(compute_rec)\n",
    "         .groupByKey()\n",
    "         .map(lambda x: (x[0],(sorted(list(y for y in x[1]),key=lambda x: -x[1]))[0:5])))\n",
    "    \n",
    "    print rec_rdd.take(2) \n",
    "    recommendations_rdd=(rec_rdd\n",
    "                     .map(map_string)\n",
    "                     .takeOrdered(k+1,key=lambda x: int(x[0])))\n",
    "    print recommendations_rdd            \n",
    "    recommended_users=list(item[0] for item in recommendations_rdd)\n",
    "    formatted_recommendations=recommendations_rdd;\n",
    "    csv_f1=csv.writer(f1)\n",
    "    m=0\n",
    "    n=0\n",
    "    while(m<k):\n",
    "        if (test_users[m] in recommended_users):\n",
    "            csv_f1.writerow(formatted_recommendations[n])\n",
    "            n+=1\n",
    "        else:\n",
    "            csv_f1.writerow((test_users[m],top))\n",
    "        m+=1\n",
    "        \n",
    "    i=i+k\n",
    "    f1.close()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#collecting results\n",
    "i=0\n",
    "rows=[[\"userId\",\"testItems\"]]\n",
    "while(i<4196):\n",
    "    f1= open('content_based/submission_content_based'+str(i)+'.csv','rb')\n",
    "    f1_csv=csv.reader(f1)\n",
    "    rows=rows+list(f1_csv)\n",
    "    if (i<=1820):i=i+20\n",
    "    else:\n",
    "        if (i<=2000):i=i+10\n",
    "            else:i=i+5\n",
    "    f1.close()\n",
    "f1=open('content_based/submission_content_based.csv','w+')\n",
    "f1_csv=csv.writer(f1)\n",
    "f1_csv.writerows(rows)\n",
    "f1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
